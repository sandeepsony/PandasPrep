{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1: House Price Prediction\n",
    "## 1. Problem Definition\n",
    "### Predict house prices based on feature like size, location, and amenities. \n",
    "### We will use linear regression model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use Boston data which is available in scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "# Load the california housing data\n",
    "housing = fetch_california_housing()\n",
    "data = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "data['PRICE'] = housing.target\n",
    "#display(data)\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nFeature names: {housing.feature_names}\")\n",
    "print(f\"\\nFirst 5 rows of our dataset: {data.head()}\")\n",
    "print(f\"\\nStatistical summary: {data.describe()}\")\n",
    "\n",
    "# Missing values -  NO MISSING VALUE\n",
    "print(f\"Missing values in each column: {data.isnull().sum()}\")\n",
    "\n",
    "# Visualize the distribution of house prices -HISTOGRAM\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data['PRICE'], kde=True, )\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.xlabel('Prices (x $100k)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "#Correlation matrix to see relationship between features\n",
    "correlation_matrix = data.corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "#Split the data into features (X) and target (y)\n",
    "X=data.drop('PRICE', axis=1)\n",
    "y=data['PRICE']\n",
    "# Split into tarining and testing sets (70% training, 30% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "#Train the model on training data\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "#Evaluate the model using test data\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Linear Regression Performance:\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Let's see the coefficients to understand feature importance\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': linear_model.coef_\n",
    "})\n",
    "coefficients = coefficients.sort_values(by='Coefficient', ascending=False)\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use LAZYPREDICT to see the top models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using LazyPredict to try multiple models quickly\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "# Initialize LazyRegressor\n",
    "reg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "# Fit and evaluate multiple models\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Display performance comparison of various models\n",
    "print(\"\\nLazyPredict Model Comparison:\")\n",
    "print(models)\n",
    "\n",
    "# Let's visualize the top performing models\n",
    "plt.figure(figsize=(12, 6))\n",
    "models_r2 = models.sort_values(by='R-Squared', ascending=False).head(10)\n",
    "sns.barplot(x=models_r2.index, y=models_r2['R-Squared'])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Top 10 Models by R-Squared')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We identified XGBoost is the top performing model, so we will train and hyperparameter tune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import XGB\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "#Initialize the XGBoost regressor\n",
    "xgb_model = xgb.XGBRegressor(random=42)\n",
    "# check basic performance with cross-validation\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='r2')\n",
    "print(f\"XGBoost cross-validation R2 score: {cv_scores}\")\n",
    "print(f\"Mean CV R2 score: {cv_scores.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "xgb_mse = mean_squared_error(y_test, xgb_pred)\n",
    "xgb_rmse = np.sqrt(xgb_mse)\n",
    "xgb_r2 = r2_score(y_test, xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "xgb.plot_importance(xgb_model)\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100,200],\n",
    "    'max_depth': [3,5,7],\n",
    "    'learning_rate': [0.1,0.05]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= xgb.XGBRegressor(random=42),\n",
    "    param_grid=param_grid,\n",
    "    cv = 3,\n",
    "    scoring='r2',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fiting the grid search and getting result\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best R2 Score: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model with best parameters\n",
    "best_xgb = grid_search.best_estimator_\n",
    "best_xgb.fit(X_train, y_train)\n",
    "# Final Evaluation\n",
    "final_pred = best_xgb.predict(X_test)\n",
    "final_r2 = r2_score(y_test, final_pred)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_pred))\n",
    "#Print final results\n",
    "print(f\"Root Mean Squared Error: {final_rmse:.4f}\")\n",
    "print(f\"R² Score: {final_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISULIZE\n",
    "# Create a DataFrame for easier plotting\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': final_pred\n",
    "})\n",
    "# Calculate prediction errors\n",
    "results_df['Error'] = results_df['Actual'] - results_df['Predicted']\n",
    "\n",
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(results_df['Actual'], results_df['Predicted'], alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Prices ($100,000s)')\n",
    "plt.ylabel('Predicted Prices ($100,000s)')\n",
    "plt.title('Actual vs Predicted House Prices')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize error distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(results_df['Error'], kde=True)\n",
    "plt.xlabel('Prediction Error ($100,000s)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize errors vs predicted values (to check for patterns)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(results_df['Predicted'], results_df['Error'], alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Prices ($100,000s)')\n",
    "plt.ylabel('Prediction Error ($100,000s)')\n",
    "plt.title('Prediction Errors vs Predicted Values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import lime \n",
    "from lime import lime_tabular\n",
    "\n",
    "# AS we already have our trained model XGBoost model (best_xgb) and our test data X_test\n",
    "\n",
    "# 1. SHAP (SHapley Additive exPlanations)\n",
    "#create a SHAP explainer for our model\n",
    "explainer = shap.TreeExplainer(best_xgb)\n",
    "shap_values = explainer.shap_values(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SHAP values for a single prediction\n",
    "plt.figure(figsize=(12,6))\n",
    "shap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:],\n",
    "                feature_names=X_test.columns, matplotlib=True)\n",
    "plt.title(\"SHAP Force plot for a single prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary plot showing impact of all features\n",
    "plt.figure(figsize=(12, 8))\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "plt.title(\"SHAP Summary Plot\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 16512 samples\n",
      "Test set: 4128 samples\n",
      "Baseline RMSE without conformal prediction: 0.4718\n",
      "y_pred shape: (4128,)\n",
      "y_pis shape: (4128, 2, 1)\n",
      "99% Prediction Interval - Average width: 1.8467\n",
      "99% Prediction Interval - Empirical coverage: 0.9380\n",
      "\n",
      "Sample predictions with intervals:\n",
      "Example 1:\n",
      "True value: 0.4770\n",
      "Predicted value: 0.5945\n",
      "99% prediction interval: [-0.3289, 1.5178]\n",
      "Interval width: 1.8467\n",
      "True value within interval: True\n",
      "\n",
      "Example 2:\n",
      "True value: 0.4580\n",
      "Predicted value: 0.7841\n",
      "99% prediction interval: [-0.1392, 1.7075]\n",
      "Interval width: 1.8467\n",
      "True value within interval: True\n",
      "\n",
      "Example 3:\n",
      "True value: 5.0000\n",
      "Predicted value: 5.1981\n",
      "99% prediction interval: [4.2748, 6.1215]\n",
      "Interval width: 1.8467\n",
      "True value within interval: True\n",
      "\n",
      "Example 4:\n",
      "True value: 2.1860\n",
      "Predicted value: 2.4398\n",
      "99% prediction interval: [1.5165, 3.3632]\n",
      "Interval width: 1.8467\n",
      "True value within interval: True\n",
      "\n",
      "Example 5:\n",
      "True value: 2.7800\n",
      "Predicted value: 2.4274\n",
      "99% prediction interval: [1.5041, 3.3508]\n",
      "Interval width: 1.8467\n",
      "True value within interval: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import MAPIE\n",
    "from mapie.regression import MapieRegressor\n",
    "\n",
    "# Assuming we have our data from Project 1\n",
    "# Convert pandas DataFrames to NumPy arrays if needed\n",
    "X_np = X.values if isinstance(X, pd.DataFrame) else X\n",
    "y_np = y.values if isinstance(y, pd.Series) else y\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_np, y_np, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Create and train an XGBoost model\n",
    "model = xgb.XGBRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make point predictions on the test set\n",
    "point_predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate baseline metrics\n",
    "baseline_rmse = np.sqrt(np.mean((y_test - point_predictions) ** 2))\n",
    "print(f\"Baseline RMSE without conformal prediction: {baseline_rmse:.4f}\")\n",
    "\n",
    "# Create and train the MAPIE regressor for conformal prediction\n",
    "mapie = MapieRegressor(model, method=\"naive\", cv=\"prefit\")\n",
    "mapie.fit(X_train, y_train)\n",
    "\n",
    "# Generate prediction intervals at 90% confidence\n",
    "alpha = 0.01  # This means 99% confidence (1 - 0.01)\n",
    "y_pred, y_pis = mapie.predict(X_test, alpha=alpha)\n",
    "\n",
    "# Print the shape to understand the format\n",
    "print(f\"y_pred shape: {y_pred.shape}\")\n",
    "print(f\"y_pis shape: {y_pis.shape}\")\n",
    "\n",
    "# Based on the shape, extract lower and upper bounds correctly\n",
    "# Let's check the dimensions and adjust accordingly\n",
    "if len(y_pis.shape) == 3:\n",
    "    lower_bound = y_pis[:, 0, 0]\n",
    "    upper_bound = y_pis[:, 1, 0]  # This might be the correction needed\n",
    "else:\n",
    "    # For 2D output\n",
    "    lower_bound = y_pis[:, 0]\n",
    "    upper_bound = y_pis[:, 1]\n",
    "\n",
    "# Calculate the width of each interval\n",
    "interval_widths = upper_bound - lower_bound\n",
    "average_width = np.mean(interval_widths)\n",
    "\n",
    "# Calculate coverage (percentage of true values inside intervals)\n",
    "coverage = np.mean((y_test >= lower_bound) & (y_test <= upper_bound))\n",
    "\n",
    "print(f\"99% Prediction Interval - Average width: {average_width:.4f}\")\n",
    "print(f\"99% Prediction Interval - Empirical coverage: {coverage:.4f}\")\n",
    "\n",
    "# Display sample predictions with intervals\n",
    "print(\"\\nSample predictions with intervals:\")\n",
    "for i in range(5):\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"True value: {y_test[i]:.4f}\")\n",
    "    print(f\"Predicted value: {y_pred[i]:.4f}\")\n",
    "    print(f\"99% prediction interval: [{lower_bound[i]:.4f}, {upper_bound[i]:.4f}]\")\n",
    "    print(f\"Interval width: {interval_widths[i]:.4f}\")\n",
    "    print(f\"True value within interval: {(y_test[i] >= lower_bound[i]) and (y_test[i] <= upper_bound[i])}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
